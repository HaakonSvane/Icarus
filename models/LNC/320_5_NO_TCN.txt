model:TCN  parameters:2238

dataset: [PosixPath('/home/leic/Desktop/tongji/Icarus_try/data/training/labeled/80H_WIN/LNC_15min.csv')] 

Begin to slice.
Successful!

training features: torch.Size([8000, 320, 5])
testing features: torch.Size([2000, 320, 5])
training labels: torch.Size([8000, 1]) tensor([0, 1, 2]) tensor([2479, 3140, 2381]) tensor([0.3099, 0.3925, 0.2976])
testing labels: torch.Size([2000, 1]) tensor([0, 1, 2]) tensor([625, 783, 592]) tensor([0.3125, 0.3915, 0.2960])

cuda = True

epoch:0 	train loss:13891.870117 	train accuracy:0.336875 	test loss:5.341292 	test accuracy:0.304500
epoch:10 	train loss:1337.096313 	train accuracy:0.334000 	test loss:2.655355 	test accuracy:0.309000
epoch:20 	train loss:1125.403442 	train accuracy:0.341625 	test loss:3.132455 	test accuracy:0.310500
epoch:30 	train loss:1013.509583 	train accuracy:0.353250 	test loss:3.130311 	test accuracy:0.301000
epoch:40 	train loss:1180.269287 	train accuracy:0.359625 	test loss:4.802291 	test accuracy:0.366000
epoch:50 	train loss:1071.129395 	train accuracy:0.352875 	test loss:2.249126 	test accuracy:0.324000
epoch:60 	train loss:1145.672241 	train accuracy:0.362750 	test loss:4.579770 	test accuracy:0.393000
epoch:70 	train loss:1713.654419 	train accuracy:0.356875 	test loss:8.736991 	test accuracy:0.320000
epoch:80 	train loss:1258.139404 	train accuracy:0.361500 	test loss:9.287066 	test accuracy:0.394000
epoch:90 	train loss:1410.953003 	train accuracy:0.352500 	test loss:4.666884 	test accuracy:0.397000
epoch:100 	train loss:1260.980957 	train accuracy:0.360500 	test loss:9.775102 	test accuracy:0.318500
epoch:110 	train loss:1397.849976 	train accuracy:0.362875 	test loss:2.453839 	test accuracy:0.360000
epoch:120 	train loss:1421.097656 	train accuracy:0.358000 	test loss:2.801009 	test accuracy:0.396000
epoch:130 	train loss:1194.152832 	train accuracy:0.378000 	test loss:10.632484 	test accuracy:0.392000
epoch:140 	train loss:1599.062500 	train accuracy:0.367500 	test loss:3.752183 	test accuracy:0.346500
epoch:150 	train loss:1095.767578 	train accuracy:0.367125 	test loss:2.955616 	test accuracy:0.312500
epoch:160 	train loss:1270.447632 	train accuracy:0.371750 	test loss:3.405145 	test accuracy:0.396000
epoch:170 	train loss:970.093811 	train accuracy:0.376000 	test loss:6.290239 	test accuracy:0.291500
epoch:180 	train loss:1178.292603 	train accuracy:0.365500 	test loss:13.324405 	test accuracy:0.396500
epoch:190 	train loss:1665.195557 	train accuracy:0.360125 	test loss:9.964109 	test accuracy:0.319000
epoch:200 	train loss:1040.606323 	train accuracy:0.381625 	test loss:3.192833 	test accuracy:0.415000
epoch:210 	train loss:1384.966309 	train accuracy:0.370750 	test loss:4.082701 	test accuracy:0.317000
epoch:220 	train loss:1211.908325 	train accuracy:0.369375 	test loss:4.000980 	test accuracy:0.336000
epoch:230 	train loss:1340.265625 	train accuracy:0.371875 	test loss:2.180117 	test accuracy:0.408500
epoch:240 	train loss:1165.330322 	train accuracy:0.377375 	test loss:7.997332 	test accuracy:0.311500
epoch:250 	train loss:930.239441 	train accuracy:0.386750 	test loss:6.449241 	test accuracy:0.313500
epoch:260 	train loss:1111.883789 	train accuracy:0.376625 	test loss:2.187334 	test accuracy:0.408000
epoch:270 	train loss:1112.607300 	train accuracy:0.382750 	test loss:3.081681 	test accuracy:0.352000
epoch:280 	train loss:1142.917480 	train accuracy:0.379250 	test loss:4.810741 	test accuracy:0.314500
epoch:290 	train loss:1105.868164 	train accuracy:0.383750 	test loss:2.562637 	test accuracy:0.407000
epoch:300 	train loss:926.880737 	train accuracy:0.391375 	test loss:4.662425 	test accuracy:0.405000
epoch:310 	train loss:1561.118042 	train accuracy:0.371625 	test loss:8.932987 	test accuracy:0.294500
epoch:320 	train loss:1248.508301 	train accuracy:0.388125 	test loss:10.695437 	test accuracy:0.314000
epoch:330 	train loss:1000.448853 	train accuracy:0.388250 	test loss:5.769430 	test accuracy:0.436500
epoch:340 	train loss:1027.278931 	train accuracy:0.390500 	test loss:3.777976 	test accuracy:0.380500
epoch:350 	train loss:1021.970215 	train accuracy:0.400375 	test loss:3.582865 	test accuracy:0.406500
epoch:360 	train loss:1056.742920 	train accuracy:0.383375 	test loss:16.438457 	test accuracy:0.422500
epoch:370 	train loss:1310.188599 	train accuracy:0.385500 	test loss:3.896518 	test accuracy:0.404000
epoch:380 	train loss:1107.900635 	train accuracy:0.383500 	test loss:3.146849 	test accuracy:0.420500
epoch:390 	train loss:1320.289185 	train accuracy:0.371625 	test loss:4.420456 	test accuracy:0.327500
epoch:400 	train loss:1312.753784 	train accuracy:0.373625 	test loss:5.394598 	test accuracy:0.330500
epoch:410 	train loss:1220.166260 	train accuracy:0.393250 	test loss:8.490690 	test accuracy:0.316000
epoch:420 	train loss:1292.220337 	train accuracy:0.382250 	test loss:5.019963 	test accuracy:0.319500
epoch:430 	train loss:1372.052124 	train accuracy:0.381875 	test loss:10.139132 	test accuracy:0.306000
epoch:440 	train loss:1123.873413 	train accuracy:0.392375 	test loss:2.958882 	test accuracy:0.353000
epoch:450 	train loss:1083.098511 	train accuracy:0.393000 	test loss:4.537095 	test accuracy:0.419000
epoch:460 	train loss:1186.017090 	train accuracy:0.387000 	test loss:17.957306 	test accuracy:0.295500
epoch:470 	train loss:927.212219 	train accuracy:0.393875 	test loss:6.038922 	test accuracy:0.402500
epoch:480 	train loss:1192.132812 	train accuracy:0.395625 	test loss:7.028438 	test accuracy:0.299000
epoch:490 	train loss:1498.464233 	train accuracy:0.377125 	test loss:8.345085 	test accuracy:0.315000

epoch:499 	train loss:1412.350220 	train accuracy:0.383000 	test loss:7.062925 	test accuracy:0.299500
320_5_NO_TCN
[[ 21  50 554]
 [ 18  59 706]
 [ 19  54 519]]
              precision    recall  f1-score   support

           0       0.36      0.03      0.06       625
           1       0.36      0.08      0.12       783
           2       0.29      0.88      0.44       592

    accuracy                           0.30      2000
   macro avg       0.34      0.33      0.21      2000
weighted avg       0.34      0.30      0.20      2000

